{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063ebd38",
   "metadata": {},
   "source": [
    "# ISP Project: Waste Collection Prediction — LSTM & BiLSTM Baselines\n",
    "\n",
    "Implement the baseline LSTM and BiLSTM approaches using the individual-bin methodology. This notebook follows the pipeline: per-bin normalization, 30-day sequences → next-day prediction, temporal 80/20 split, and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ef6e1c",
   "metadata": {},
   "source": [
    "## Problems the Original Paper Leaves Ambiguous\n",
    "\n",
    "- **Dataset preprocessing:** exact gap handling and resampling to daily cadence.\n",
    "- **Individual vs collective prediction:** how per-bin scaling and splitting are managed.\n",
    "- **Temporal splitting:** exact strategy to avoid leakage and keep chronology.\n",
    "\n",
    "### My Solution (LSTM/BiLSTM version)\n",
    "1. Deep dataset audit: read cleaned dataset and confirm coverage.\n",
    "2. Daily continuity: gap-filling to ensure continuous daily series per bin, then 30-day windows.\n",
    "3. Per-bin normalization: MinMax scaling per bin.\n",
    "4. Temporal 80/20 split: chronological split per bin for train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7041f18",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 15) (1716723454.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 15)\n"
     ]
    }
   ],
   "source": [
    "# Imports & paths\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_CSV = \"../../data/wyndham_waste_data_cleaned.csv\"\n",
    "RESULTS_JSON = \"../../outputs/lstm_bilstm_comparison.json\"\n",
    "LSTM_PNG = \"../../outputs/lstm_training_results.png\"\n",
    "BILSTM_PNG = \"../../outputs/bilstm_training_results.png\"\n",
    "\n",
    "# Pretty printing helpers\n",
    "def hr(title):\n",
    "    print(\"\\n\" + title)\n",
    "    print(\"=\" * len(title))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde2264",
   "metadata": {},
   "source": [
    "## Implementation Details (recap)\n",
    "\n",
    "- Input -> per-bin daily timeline -> MinMax per-bin -> 30-day sliding windows -> chronological 80/20 split.\n",
    "\n",
    "### Baseline Architectures (paper-faithful)\n",
    "- LSTM: Input (30, 1) → LSTM(100) → Dropout(0.2) → Dense(1)\n",
    "- BiLSTM: Input (30, 1) → Bidirectional(LSTM(100)) → Dropout(0.2) → Dense(1)\n",
    "- Training: Adam(lr=5e-4), MSE, epochs=20, batch=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce615857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model results (generated by the training script)\n",
    "if os.path.exists(RESULTS_JSON):\n",
    "    with open(RESULTS_JSON, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "else:\n",
    "    # Fallback: populate with console metrics if JSON isn't present\n",
    "    results = {\n",
    "        \"LSTM\": {\n",
    "            \"train_metrics\": {\"MAE\": 1.836, \"MAPE\": np.nan, \"RMSE\": 2.375, \"R2\": 0.480},\n",
    "            \"test_metrics\":  {\"MAE\": 1.987, \"MAPE\": np.nan, \"RMSE\": 2.575, \"R2\": 0.418},\n",
    "        },\n",
    "        \"BiLSTM\": {\n",
    "            \"train_metrics\": {\"MAE\": 1.816, \"MAPE\": np.nan, \"RMSE\": 2.361, \"R2\": 0.486},\n",
    "            \"test_metrics\":  {\"MAE\": 1.965, \"MAPE\": np.nan, \"RMSE\": 2.563, \"R2\": 0.423},\n",
    "        },\n",
    "    }\n",
    "\n",
    "hr(\"Loaded Results (from JSON or fallback)\")\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686219ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: read dataset stats (if CSV available)\n",
    "dataset_info = {}\n",
    "if os.path.exists(DATA_CSV):\n",
    "    df = pd.read_csv(DATA_CSV)\n",
    "    # Expect columns: timestamp, latestFullness, serialNumber, ...\n",
    "    try:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"timestamp\", \"latestFullness\", \"serialNumber\"])\n",
    "        bins = df[\"serialNumber\"].nunique()\n",
    "        date_min, date_max = df[\"timestamp\"].min(), df[\"timestamp\"].max()\n",
    "        dataset_info = {\n",
    "            \"Total Records\": f\"{len(df):,}\",\n",
    "            \"Unique Bins\": f\"{bins}\",\n",
    "            \"Date Range\": f\"{date_min.date()} to {date_max.date()}\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        dataset_info = {\"Note\": f\"Could not parse dataset due to: {e}\"}\n",
    "else:\n",
    "    dataset_info = {\"Note\": \"CSV not found. Skipping dataset stats.\"}\n",
    "\n",
    "hr(\"Dataset Snapshot\")\n",
    "print(dataset_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a13d1b",
   "metadata": {},
   "source": [
    "## Training Configuration (Applied)\n",
    "- Epochs: 20\n",
    "- Batch size: 70\n",
    "- Sequence length: 30\n",
    "- Optimizer: Adam (lr = 5e-4)\n",
    "- Loss: MSE\n",
    "- Normalization: Per-bin MinMax (0–1), inverse for metrics on 0–10 scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7536fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a tidy comparison table (Our LSTM vs Our BiLSTM vs Paper)\n",
    "paper_ref = {\n",
    "    \"LSTM\":   {\"RMSE\": 1.579, \"MAE\": 0.602, \"MAPE(%)\": 1.86, \"R2\": 0.93},\n",
    "    \"BiLSTM\": {\"RMSE\": 1.543, \"MAE\": 0.638, \"MAPE(%)\": 7.95, \"R2\": 0.90},\n",
    "}\n",
    "\n",
    "def safe_pct(x):\n",
    "    return None if (x is None or (isinstance(x, float) and np.isnan(x))) else 100.0 * x\n",
    "\n",
    "rows = []\n",
    "for model_name in [\"LSTM\", \"BiLSTM\"]:\n",
    "    ours_tr = results[model_name][\"train_metrics\"]\n",
    "    ours_te = results[model_name][\"test_metrics\"]\n",
    "    rows.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Split\": \"Train\",\n",
    "        \"RMSE\": ours_tr[\"RMSE\"],\n",
    "        \"MAE\":  ours_tr[\"MAE\"],\n",
    "        \"MAPE(%)\": safe_pct(ours_tr.get(\"MAPE\")),\n",
    "        \"R²\":   ours_tr[\"R2\"],\n",
    "    })\n",
    "    rows.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Split\": \"Test\",\n",
    "        \"RMSE\": ours_te[\"RMSE\"],\n",
    "        \"MAE\":  ours_te[\"MAE\"],\n",
    "        \"MAPE(%)\": safe_pct(ours_te.get(\"MAPE\")),\n",
    "        \"R²\":   ours_te[\"R2\"],\n",
    "    })\n",
    "    rows.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Split\": \"Paper (Ref.)\",\n",
    "        \"RMSE\": paper_ref[model_name][\"RMSE\"],\n",
    "        \"MAE\":  paper_ref[model_name][\"MAE\"],\n",
    "        \"MAPE(%)\": paper_ref[model_name][\"MAPE(%)\"],\n",
    "        \"R²\":   paper_ref[model_name][\"R2\"],\n",
    "    })\n",
    "\n",
    "comp_df = pd.DataFrame(rows)\n",
    "\n",
    "hr(\"Performance Comparison Table\")\n",
    "# Pretty display if in notebook environment\n",
    "try:\n",
    "    display(comp_df.style.format({\"RMSE\": \"{:.3f}\", \"MAE\": \"{:.3f}\", \"MAPE(%)\": lambda v: \"-\" if v is None else f\"{v:.2f}\",\n",
    "                                  \"R²\": \"{:.3f}\"}))\n",
    "except Exception:\n",
    "    print(comp_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar charts: R² and RMSE on Test split (Our vs Paper)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "test_slice = comp_df[comp_df[\"Split\"].isin([\"Test\", \"Paper (Ref.)\"]) ]\n",
    "\n",
    "# RMSE\n",
    "for i, model_name in enumerate([\"LSTM\", \"BiLSTM\"]):\n",
    "    subset = test_slice[test_slice[\"Model\"] == model_name]\n",
    "    axes[0].bar([i*2, i*2+1], subset[\"RMSE\"], width=0.8, label=model_name if i==0 else \"\")\n",
    "axes[0].set_xticks([0,1,2,3])\n",
    "axes[0].set_xticklabels([\"LSTM (Ours)\", \"LSTM (Paper)\", \"BiLSTM (Ours)\", \"BiLSTM (Paper)\"], rotation=15)\n",
    "axes[0].set_ylabel(\"RMSE (0–10 scale)\")\n",
    "axes[0].set_title(\"RMSE — Test\")\n",
    "axes[0].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# R²\n",
    "for i, model_name in enumerate([\"LSTM\", \"BiLSTM\"]):\n",
    "    subset = test_slice[test_slice[\"Model\"] == model_name]\n",
    "    axes[1].bar([i*2, i*2+1], subset[\"R²\"], width=0.8, label=model_name if i==0 else \"\")\n",
    "axes[1].set_xticks([0,1,2,3])\n",
    "axes[1].set_xticklabels([\"LSTM (Ours)\", \"LSTM (Paper)\", \"BiLSTM (Ours)\", \"BiLSTM (Paper)\"], rotation=15)\n",
    "axes[1].set_ylabel(\"R²\")\n",
    "axes[1].set_title(\"R² — Test\")\n",
    "axes[1].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f7778",
   "metadata": {},
   "source": [
    "## Training Curves (from Saved Runs)\n",
    "If available, the plots below are identical to those produced during training (`lstm_training_results.png` and `bilstm_training_results.png`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cfd183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_if_exists(path, title):\n",
    "    if os.path.exists(path):\n",
    "        img = plt.imread(path)\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"[info] Plot not found at: {path}\")\n",
    "\n",
    "show_image_if_exists(LSTM_PNG,  \"LSTM — Training Results\")\n",
    "show_image_if_exists(BILSTM_PNG, \"BiLSTM — Training Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba22ad8",
   "metadata": {},
   "source": [
    "## Key Findings (LSTM & BiLSTM)\n",
    "\n",
    "1. Consistent convergence; both models show steadily decreasing loss.\n",
    "2. BiLSTM marginally outperforms LSTM on RMSE and R².\n",
    "3. R² ≈ 0.42 (test) suggests moderate predictability.\n",
    "4. Absolute errors larger than paper, likely due to preprocessing differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a6903",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Add exogenous features (holidays, weather).\n",
    "- Evaluate multivariate models with more features.\n",
    "- Calibrate collection thresholds via cost-sensitive evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
